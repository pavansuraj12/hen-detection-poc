<!DOCTYPE html>
<html>
<head>
  <title>YOLO Hen Detection â€” Production Tracking</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <style>
    body {
      margin: 0;
      padding: 0;
      background: #111;
      color: white;
      font-family: Arial, sans-serif;
      text-align: center;
    }

    .camera-box {
      position: relative;
      width: 416px;
      height: 416px;
      margin: 20px auto;
      border: 2px solid #444;
    }

    video {
      width: 416px;
      height: 416px;
      display: block;
    }

    canvas {
      position: absolute;
      top: 0;
      left: 0;
      pointer-events: none;
    }

    .status {
      font-size: 13px;
      margin-top: 8px;
    }
  </style>
</head>

<body>

<h3>YOLO Hen Detection (Production-Grade Tracking)</h3>

<div class="camera-box">
  <video id="video" autoplay muted playsinline></video>
  <canvas id="overlay"></canvas>
</div>

<button onclick="startLive()">Start</button>
<button onclick="stopLive()">Stop</button>

<div class="status" id="status">Idle</div>

<script>
/* ================= CONFIG ================= */
const SIZE = 416;
const BACKEND_URL = "https://unraided-camren-streamingly.ngrok-free.dev/predict";
const DETECT_INTERVAL = 400;
const TRACK_TTL = 6;
const IOU_THRESHOLD = 0.3;
const PREDICTION_DAMPING = 0.9; // smooth motion

/* ================= ELEMENTS ================= */
const video = document.getElementById("video");
const canvas = document.getElementById("overlay");
const ctx = canvas.getContext("2d");
const statusText = document.getElementById("status");

/* DPR fix */
const dpr = window.devicePixelRatio || 1;
canvas.width = SIZE * dpr;
canvas.height = SIZE * dpr;
canvas.style.width = SIZE + "px";
canvas.style.height = SIZE + "px";
ctx.scale(dpr, dpr);

/* Capture canvas */
const cap = document.createElement("canvas");
cap.width = SIZE;
cap.height = SIZE;
const capCtx = cap.getContext("2d");

/* ================= STATE ================= */
let running = false;
let detectTimer = null;
let tracks = [];
let nextTrackId = 1;

/* ================= START ================= */
async function startLive() {
  if (running) return;

  const stream = await navigator.mediaDevices.getUserMedia({
    video: { facingMode: { ideal: "environment" } }
  });

  video.srcObject = stream;

  video.onloadedmetadata = () => {
    video.play();
    running = true;
    detectLoop();
    requestAnimationFrame(renderLoop);
    statusText.innerText = "Live";
  };
}

/* ================= STOP ================= */
function stopLive() {
  running = false;
  clearTimeout(detectTimer);

  if (video.srcObject) {
    video.srcObject.getTracks().forEach(t => t.stop());
    video.srcObject = null;
  }

  tracks = [];
  ctx.clearRect(0, 0, SIZE, SIZE);
  statusText.innerText = "Stopped";
}

/* ================= DETECTION LOOP ================= */
function detectLoop() {
  if (!running) return;

  capCtx.drawImage(video, 0, 0, SIZE, SIZE);

  cap.toBlob(async blob => {
    if (!blob) return;

    const fd = new FormData();
    fd.append("image", blob, "frame.jpg");

    try {
      const res = await fetch(BACKEND_URL, { method: "POST", body: fd });
      const data = await res.json();
      updateTracks(data.detections);
    } catch {}

    detectTimer = setTimeout(detectLoop, DETECT_INTERVAL);
  }, "image/jpeg", 0.9);
}

/* ================= IOU ================= */
function iou(a, b) {
  const xA = Math.max(a[0], b[0]);
  const yA = Math.max(a[1], b[1]);
  const xB = Math.min(a[2], b[2]);
  const yB = Math.min(a[3], b[3]);

  const inter = Math.max(0, xB - xA) * Math.max(0, yB - yA);
  const areaA = (a[2] - a[0]) * (a[3] - a[1]);
  const areaB = (b[2] - b[0]) * (b[3] - b[1]);

  return inter / (areaA + areaB - inter + 1e-6);
}

/* ================= TRACK UPDATE + VELOCITY ================= */
function updateTracks(detections) {
  const now = performance.now();

  // Decay TTL
  tracks.forEach(t => t.ttl--);

  const usedTracks = new Set();

  detections.forEach(det => {
    let bestMatch = null;
    let bestIou = 0;

    tracks.forEach(track => {
      if (usedTracks.has(track.id)) return;
      const score = iou(track.bbox, det.bbox);
      if (score > bestIou) {
        bestIou = score;
        bestMatch = track;
      }
    });

    if (bestMatch && bestIou > IOU_THRESHOLD) {
      const dt = (now - bestMatch.lastUpdateTime) / 1000;

      // Estimate velocity
      if (dt > 0) {
        bestMatch.velocity = bestMatch.bbox.map(
          (v, i) => (det.bbox[i] - v) / dt
        );
      }

      bestMatch.bbox = det.bbox;
      bestMatch.lastUpdateTime = now;
      bestMatch.confidence = det.confidence;
      bestMatch.ttl = TRACK_TTL;
      usedTracks.add(bestMatch.id);
    } else {
      // New track
      tracks.push({
        id: nextTrackId++,
        bbox: det.bbox,
        velocity: [0, 0, 0, 0],
        lastUpdateTime: now,
        confidence: det.confidence,
        ttl: TRACK_TTL,
        age: 0
      });
    }
  });

  tracks = tracks.filter(t => t.ttl > 0);
}

/* ================= RENDER + PREDICTION ================= */
function renderLoop() {
  if (!running) return;

  const now = performance.now();

  ctx.clearRect(0, 0, SIZE, SIZE);
  ctx.lineWidth = 2;
  ctx.font = "14px Arial";
  ctx.strokeStyle = "lime";
  ctx.fillStyle = "lime";

  tracks.forEach(t => {
    const dt = (now - t.lastUpdateTime) / 1000;

    // Predict next position
    const predicted = t.bbox.map(
      (v, i) => v + t.velocity[i] * dt * PREDICTION_DAMPING
    );

    ctx.strokeRect(
      predicted[0],
      predicted[1],
      predicted[2] - predicted[0],
      predicted[3] - predicted[1]
    );

    ctx.fillText(
      `Hen ${t.id}`,
      predicted[0],
      Math.max(15, predicted[1] - 5)
    );

    t.age++;
  });

  statusText.innerText = `Active tracks: ${tracks.length}`;
  requestAnimationFrame(renderLoop);
}
</script>

</body>
</html>
